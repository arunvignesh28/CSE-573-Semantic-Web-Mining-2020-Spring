# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jjrx-4AaV5VkZKi8C5VnMIOAds2QS-UC
"""



import pandas as pd
import numpy as np
import math
import sys
from sklearn.metrics import mean_squared_error
def rmse(prediction, ground_truth):
    prediction = prediction[ground_truth.nonzero()].flatten()
    ground_truth = ground_truth[ground_truth.nonzero()].flatten()
    return math.sqrt(mean_squared_error(prediction, ground_truth))
def predictions(P, Q):
  return np.dot(P.T, Q)
def fit(X_train, X_val):
  m, n = X_train.shape
  n_latent_features = 40
  P = 3 * np.random.rand(n_latent_features, m)
  Q = 3 * np.random.rand(n_latent_features, n)
  # print(P)
  # print(Q)
  train_error = []
  val_error = []
  lmbda =0.0
  users, items = X_train.nonzero()
  learning_rate = 0.00001
  for epoch in range(100):
      for u, i in zip(users, items):
          #print(predictions(P[:,u], Q[:,i]))
          
          #exit(0)
          #print(P[:, u])
          #print(Q[:, i])
          error = X_train[u, i] - predictions(P[:,u], Q[:,i])
          #print(error)
          
          P[:, u] += learning_rate * \
           (error * Q[:, i] - lmbda * P[:, u])
          Q[:, i] +=  learning_rate * \
           (error * P[:, u] - lmbda * Q[:, i])
         
          
      #print(predictions(P, Q))
     # sys.exit()
      train_rmse = rmse(predictions(P, Q), X_train)
      val_rmse = rmse(predictions(P, Q), X_val)
      train_error.append(train_rmse)
      val_error.append(val_rmse)
  return train_error, val_error, P, Q

def train_test_split(ratings):
    #print(ratings.shape)
    test = np.zeros(ratings.shape)
    train = ratings.copy()
    for user in range(ratings.shape[0]):
        test_ratings = np.random.choice(ratings[user, :].nonzero()[0], 
                                        size=10, 
                                        replace=False)
        train[user, test_ratings] = 0.
        test[user, test_ratings] = ratings[user, test_ratings]
        
    # Test and training are truly disjoint
    assert(np.all((train * test) == 0)) 
    return train, test


names = ['user_id', 'item_id', 'rating', 'timestamp']
df = pd.read_csv("ml-100k/u.data", sep='\t', names=names)
#print(df)
ratings_df = df.pivot(
    index='user_id',
    columns='item_id',
    values='rating'
)

ratings = ratings_df.fillna(0).values
#print(ratings)

sparsity = float(len(ratings.nonzero()[0]))
sparsity /= (ratings.shape[0] * ratings.shape[1])
sparsity *= 100
#print('{:.2f}%'.format(sparsity))
train, val = train_test_split(ratings)
#print(train)
#print(val)
train_error, val_error, P, Q = fit(train, val)


def predict(X_train, user_index):
  y_hat = predictions(P, Q)
  predictions_index = np.where(X_train[user_index, :] == 0)[0]
  return y_hat[user_index, predictions_index].flatten()



def predictForUser(userId):
    #print(ratings_df)
    user_index = ratings_df.index.get_loc(userId)
    #predictions_index = np.where(train[user_index, :] == 0)[0]
    existing_ratings_index = np.where(train[user_index, :] > 0)[0]
    existing_ratings = train[user_index, existing_ratings_index]
    #print(existing_ratings)
    rating_predictions = predict(train, user_index)
    #print(rating_predictions)
    movies_predicted = rating_predictions.argsort()[-10:][::-1]
    #print(movies_predicted)
    movies = pd.read_csv('ml-100k/u.item', sep='|',  encoding='latin-1')
    #print(movies)
    predicted =  movies[movies.iloc[:,0].isin(movies_predicted)]
    print(predicted.iloc[:, 1])
    return predicted.iloc[:, 1].tolist()[:10]
